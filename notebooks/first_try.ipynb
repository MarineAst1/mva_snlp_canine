{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First attempt at using CANINE\n",
    "\n",
    "This notebook is a first test to use CANINE, the idea is to reproduce the results presented in the paper, as well as doing other experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random as rd\n",
    "\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import (\n",
    "    CanineForSequenceClassification,\n",
    "    CanineTokenizer,\n",
    "    DataCollatorWithPadding,\n",
    ")\n",
    "\n",
    "torch.set_float32_matmul_precision(\"medium\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using unk_token, but it is not set yet.\n",
      "Using unk_token, but it is not set yet.\n",
      "Using unk_token, but it is not set yet.\n",
      "Using unk_token, but it is not set yet.\n",
      "Using unk_token, but it is not set yet.\n",
      "Using unk_token, but it is not set yet.\n",
      "Using unk_token, but it is not set yet.\n",
      "Using unk_token, but it is not set yet.\n",
      "Some weights of CanineForSequenceClassification were not initialized from the model checkpoint at google/canine-c and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = CanineTokenizer.from_pretrained(\"google/canine-c\")\n",
    "model = CanineForSequenceClassification.from_pretrained(\"google/canine-c\", num_labels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\n",
    "    \"train\"\n",
    "].info.description += f\"\"\"\n",
    "This dataset is a subset of the XNLI dataset. It contains {num_train_samples} samples and only the following languages: {train_language_subset}, with the following probabilities: {train_probs}.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset xnli (C:/Users/gabri/.cache/huggingface/datasets/xnli/fr/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50717acce8cb4edbb785dd838947f43c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\"xnli\", \"all_languages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "language_to_abbr = {\n",
    "    \"english\": \"en\",\n",
    "    \"arabic\": \"ar\",\n",
    "    \"french\": \"fr\",\n",
    "    \"spanish\": \"es\",\n",
    "    \"german\": \"de\",\n",
    "    \"greek\": \"el\",\n",
    "    \"bulgarian\": \"bg\",\n",
    "    \"russian\": \"ru\",\n",
    "    \"turkish\": \"tr\",\n",
    "    \"chinese\": \"zh\",\n",
    "    \"thai\": \"th\",\n",
    "    \"vietnamese\": \"vi\",\n",
    "    \"hindi\": \"hi\",\n",
    "    \"urdu\": \"ur\",\n",
    "    \"swahili\": \"sw\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_samples = 50000\n",
    "train_language_subset = [\"en\", \"fr\", \"ar\", \"hi\", \"el\", \"ru\", \"tr\", \"zh\"]\n",
    "train_probs = [0.5, 0.3, 0.05, 0.05, 0.025, 0.025, 0.025, 0.025]\n",
    "test_language_subset = [\"en\", \"fr\", \"es\", \"bg\", \"th\", \"ur\", \"sw\"]\n",
    "test_probs = [0.5, 0.3, 0.075, 0.05, 0.025, 0.025, 0.025]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_hypothesis_format(example):\n",
    "    print(example[\"hypothesis\"])\n",
    "    example[\"hypothesis_dict\"] = {\n",
    "        k: v\n",
    "        for k, v in zip(\n",
    "            example[\"hypothesis\"][\"language\"], example[\"hypothesis\"][\"translation\"]\n",
    "        )\n",
    "    }\n",
    "    return example\n",
    "\n",
    "\n",
    "def choose_language(\n",
    "    example,\n",
    "    languages,\n",
    "    probs,\n",
    "):\n",
    "    from numpy.random import choice\n",
    "\n",
    "    lang = choice(languages, p=probs)\n",
    "    example[\"language\"] = lang\n",
    "    example[\"choosen_premise\"] = example[\"premise\"][lang]\n",
    "    example[\"choosen_hypothesis\"] = example[\"hypothesis_dict\"][lang]\n",
    "\n",
    "    return example\n",
    "\n",
    "\n",
    "def tokenize_dataset(example, tokenizer):\n",
    "    return tokenizer(\n",
    "        text=example[\"choosen_premise\"],\n",
    "        text_pair=example[\"choosen_hypothesis\"],\n",
    "        truncation=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15b28e2b968a4a4bba4daaf7eb6a11c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=10):   0%|          | 0/392702 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset[\"train\"] = dataset[\"train\"].map(change_hypothesis_format, num_proc=10)\n",
    "dataset[\"validation\"] = dataset[\"validation\"].map(change_hypothesis_format, num_proc=10)\n",
    "dataset[\"test\"] = dataset[\"test\"].map(change_hypothesis_format, num_proc=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"train\"] = dataset[\"train\"].map(\n",
    "    choose_language,\n",
    "    fn_kwargs={\"languages\": train_language_subset, \"probs\": train_probs},\n",
    "    batched=False,\n",
    "    num_proc=10,\n",
    ")\n",
    "dataset[\"validation\"] = dataset[\"validation\"].map(\n",
    "    choose_language,\n",
    "    fn_kwargs={\"languages\": train_language_subset, \"probs\": train_probs},\n",
    "    batched=False,\n",
    "    num_proc=10,\n",
    ")\n",
    "dataset[\"test\"] = dataset[\"test\"].map(\n",
    "    choose_language,\n",
    "    fn_kwargs={\"languages\": test_language_subset, \"probs\": test_probs},\n",
    "    batched=False,\n",
    "    num_proc=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22ec3cdf6a5b4e549e31a0398b225a2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/392702 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c60144b116994eb49aaec0906dd26d4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5010 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee33e758bedb4cd4993f83eff5994b76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2490 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = dataset.map(tokenize_dataset, batched=True, with_indices=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(\n",
    "    tokenizer=tokenizer, padding=True, max_length=2045, return_tensors=\"pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cebcbee478f43098d9d592109772e72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/392702 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 0\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"].filter(lambda x: x[\"input_ids\"] == [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': ClassLabel(names=['entailment', 'neutral', 'contradiction'], id=None),\n",
       " 'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None),\n",
       " 'token_type_ids': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None),\n",
       " 'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None)}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 20000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 1500\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at C:\\Users\\gabri\\.cache\\huggingface\\datasets\\xnli\\fr\\1.1.0\\818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd\\cache-79b8f6683ce4a7c8.arrow\n"
     ]
    }
   ],
   "source": [
    "# dataset[\"train\"] = dataset[\"train\"].remove_columns([\"premise\", \"hypothesis\"])\n",
    "dataset[\"train\"] = dataset[\"train\"].shuffle(seed=42).select(range(20000))\n",
    "dataset[\"validation\"] = dataset[\"validation\"].shuffle(seed=42).select(range(2000))\n",
    "dataset[\"test\"] = dataset[\"test\"].shuffle(seed=42).select(range(1500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    dataset[\"train\"],\n",
    "    batch_size=8,\n",
    "    collate_fn=data_collator,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[57344,    80,   111,  ...,     0,     0,     0],\n",
       "        [57344,    83,   105,  ...,     0,     0,     0],\n",
       "        [57344,    82,   105,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [57344,    79,   117,  ...,     0,     0,     0],\n",
       "        [57344,    78,   111,  ...,     0,     0,     0],\n",
       "        [57344,    72,   111,  ...,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([2, 1, 0, 1, 2, 1, 2, 1])}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XNLIModel(pl.LightningModule):\n",
    "    def __init__(self, model, dataset, data_collator, num_workers=4, batch_size=8):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.dataset = dataset\n",
    "        self.data_collator = data_collator\n",
    "        self.num_workers = num_workers\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def forward(self, **inputs):\n",
    "        return self.model(**inputs)\n",
    "\n",
    "    def get_loss(self, batch, batch_id, step):\n",
    "        outputs = self(**batch)\n",
    "        loss = outputs.loss\n",
    "        self.log(f\"{step}_loss\", loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self.get_loss(batch, batch_idx, \"train\")\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        return self.get_loss(batch, batch_idx, \"val\")\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        return self.get_loss(batch, batch_idx, \"test\")\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=1e-5)\n",
    "\n",
    "    def get_loader(self, split):\n",
    "        return DataLoader(\n",
    "            self.dataset[split],\n",
    "            batch_size=self.batch_size,\n",
    "            collate_fn=self.data_collator,\n",
    "            shuffle=(split == \"train\"),\n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=True,\n",
    "        )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return self.get_loader(\"train\")\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return self.get_loader(\"validation\")\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return self.get_loader(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "lit_model = XNLIModel(model, dataset, data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gabri\\miniconda3\\envs\\pytorch-2.0\\lib\\site-packages\\lightning_fabric\\connector.py:562: UserWarning: 16 is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!\n",
      "  rank_zero_warn(\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Running in `fast_dev_run` mode: will run the requested loop using 1 batch(es). Logging and checkpointing is suppressed.\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    accelerator=\"gpu\",\n",
    "    max_epochs=3,\n",
    "    accumulate_grad_batches=4,\n",
    "    callbacks=[\n",
    "        pl.callbacks.ModelCheckpoint(),\n",
    "        pl.callbacks.EarlyStopping(monitor=\"val_loss\", patience=3),\n",
    "        pl.callbacks.LearningRateMonitor(logging_interval=\"step\"),\n",
    "    ],\n",
    "    precision=16,\n",
    "    fast_dev_run=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model=lit_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mva-snlp-canine-JqMbT94n-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
